---
title: "K-Nearest-Neighbors"
format:
  revealjs: 
    theme: [default, spring.scss]
    incremental: true 
    output-file: slides-08-knn.html
    shift-heading-level-by: -1
execute:
  echo: true
---

```{python}

```

```{r}
#| include: false
library(reticulate)
use_python("/usr/local/bin/python3")
```

```{python}
#| include: false
import numpy as np
import pandas as pd
from plotnine import *
```

## The story so far

### Steps for data analysis

* **Read** and then **clean** the data
  + Are there missing values?  Will we drop those rows, or replace the missing values with something?
  + Are there *quantitative* variables that python thinks are *categorical*?
  + Are there *categorical* variables that python thinks are *quantitative*?
  + Are there any *anomalies* in the data that concern you?
  
### Steps for data analysis (cont'd)

* **Explore** the data by **visualizing** and **summarizing**.
  + Different approaches for different combos of *quantitative* and *categorical* variables
  + Think about *conditional* calculations (split-apply-combine)
  
### Steps for data analysis (cont'd)

* Identify a **research question** of interest.

* Perform **preprocessing** steps
  + Should we *scale* the quantitative variables?
  + Should we *one-hot-encode* the categorical variables?
  + Should we *log-transform* any variables?


* Measure similarity between **observations** by calculating **distances**.
  + Which *features* should be included?
  + Which *distance metric* should we use?

## Predicting wine prices

### Data:  Wine qualities

```{python}
df = pd.read_csv("https://dlsun.github.io/pods/data/bordeaux.csv")
df
```

### Data: Wine qualities

* Our goal is to **predict** what will be the quality (price) of wines in a **future year**.

* Idea:  Wines with similar **features** probably have similar **quality**.

* **Inputs**: Summer temperature, harvest rainfall, september temperature, winter rainfall, age of wine.

* **Output:** Price in 1992.

* "Inputs" = "Features" = "Predictors" = "Independent variables"

* "Output" = "Target" = "Dependent variable"

### Similar wines

Which wines have similar summer temps and winter rainfall to the 1989 vintage?

```{python}
#| code-fold: true
from plotnine import *

(ggplot(df, aes(x = "summer", y = "win"))
+ geom_point(color = "white")
+ geom_text(aes(label = "year"))
+ theme_classic())
```

### Predicting 1989

```{python}
df[df['year'] == 1990]

df[df['year'] == 1976]
```


### Training and test data

* The data for which we **know the target** is called the **training data**.

* The data for which we **don't know the target**  (and want to predict it) is calledthe **test data**.

``` {python}
known_prices = df['year'] < 1981
to_predict = df['year'] == 1989

df_train = df[known_prices].copy()
df_test = df[to_predict].copy()
```

### Specify steps

First we make a column transformer...

```{python}
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

preproc = make_column_transformer(
  (StandardScaler(), ['summer', 'har', 'sep', 'win','age']),
  remainder = "drop"
)
```

### Fit the preprocesser

Then we **fit** it on the **training data**

```{python}
preproc.fit(df_train)

preproc.named_transformers_['standardscaler'].mean_
preproc.named_transformers_['standardscaler'].var_
```
### Prep the data

Then we **tranform** the **training data** AND the **test data**:

```{python}
train_new = preproc.transform(df_train)
test_new = preproc.transform(df_test)

test_new
```

### Fitting vs transforming

What if we had fit on the test data?

```{python}
preproc.fit(df_test)

preproc.named_transformers_['standardscaler'].mean_
preproc.named_transformers_['standardscaler'].var_
```

### Fitting vs transforming

What if we had fit on the test data?

```{python}
preproc.transform(df_test)
```

### All together:

```{python}
preproc = make_column_transformer(
  (StandardScaler(), ['summer', 'har', 'sep', 'win','age']),
  remainder = "drop"
)

preproc.fit(df_train)

train_new = preproc.transform(df_train)
test_new = preproc.transform(df_test)
```


### Find the closest *k*

```{python}
from sklearn.metrics import pairwise_distances

pairwise_distances(test_new, train_new)
```

### Find the closest *k*

```{python}
dists = pairwise_distances(test_new, train_new)

dists[0].argsort()
```

### Find the closest *k*

```{python}
ranked_train = df_train.loc[dists[0].argsort()]
ranked_train
```
### Predict from the closest *k*

If $k = 1$ ...

```{python}
ranked_train = df_train.loc[dists[0].argsort()]
ranked_train.iloc[0]['price']
```


### Predict from the closest *k*

If $k = 100$ ...

```{python}
ranked_train = df_train.loc[dists[0].argsort()]
ranked_train.iloc[0:99]['price'].mean()
```


### Predict from the closest *k*

If $k = 5$ ...

```{python}
ranked_train = df_train.loc[dists[0].argsort()]
ranked_train.iloc[0:4]['price'].mean()
```


## Activity

### Activity 1

Find the predicted 1992 price for *all* the unknown wines, with

* $k = 1$

* $k = 5$

* $k = 10$

How close was each prediction to the right answer?

*(Optional hint: Write a function to help you!)*

### Activity 2 (together)

Find the predicted 1992 price for all the *training data*, with

* $k = 1$

* $k = 5$

* $k = 10$

How close was each prediction to the right answer?

*(Optional hint: Write a function to help you!)*


## K-Nearest-Neighbors

### KNN{.smaller}

We have existing observations

$$(X_1, y_1), ... (X_n, y_n)$$
Where $X_i$ is a set of features, and $y_i$ is a target value.

Given a new observation $X_{new}$, how do we predict $y_{new}$?

1.  Find the $k$ values in $(X_1, ..., X_n)$ that are closest to $X_{new}$

2.  Take the average of the corresponding $y_i$'s to our five closest $X_i$'s.

3. Predict $\hat{y}_{new}$ = average of these $y_i$'s

### KNN

To perform **K-Nearest-Neighbors**, we choose the **K** closest observations to our *target*, and we average their *response* values.

The Big Questions:

* What is our definition of **closest**?

* What number should we use for **K**?

* How do we evaluate the **success** of this approach?


### KNN in sklearn

```{python}
from sklearn.neighbors import KNeighborsRegressor
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(
  preproc,
  KNeighborsRegressor(n_neighbors=5)
  )
          
pipeline
```
### KNN in sklearn

```{python}
pipeline.fit(y = df_train['price'], X = df_train)
pipeline.predict(X=df_test)
```



### Activity 2

Find the predicted 1992 price for *all wines*, with

* $k = 1$

* $k = 5$

* $k = 10$

How close was each prediction to the right answer?

