---
title: "Webscraping"
format:
  revealjs: 
    theme: [default, spring.scss]
    incremental: true 
    output-file: slides-16-webscraping.html
    shift-heading-level-by: -1
execute:
  echo: true
---

```{python}

```

```{r}
#| include: false
library(reticulate)
use_python("/usr/local/bin/python3")
```

```{python}
#| include: false
import numpy as np
import pandas as pd
from plotnine import *
```


## HTML

### HyperText Markup Language (HTML){.smaller}

*   HTML is the standard language for describing the layout of webpages.

*   It is like XML, with special "tags" for hyperlinks, tables, images, etc.

* You don't need to be an HTML expert to scrape webpages, but you do need to know a few basics.
    
* You can view the HTML of a website by:
    + Putting `view-source:` in front of the url
    + Right-click and choose "View Page Source" 

* You can explore HTML "interactively" by 
    + Right-click and "inspect" 
    + Ctrl/Cmd+Shift+I

### Hyperlinks

The `<a>` **tag** indicates a (hyper)link.

-   The `href=` **attribute** contains the URL.

-   The displayed text is within the `<a>` tag.

-   <a href="www.kelly-bodwin.com">This is a link</a>


### Tables

The `<table>` tag indicates a table.

* The `<tr>` tag indicates a row.

* The `<th>` and `<td>` tags indicate a cell within a row.

* Don't forget that each tag also has a *closing tag* (`</table>`) at the end!

### Tables

::::{.columns}

:::{.column width="50%"}

```
<table>
  <tr>
    <th>Rank</th>
    <th>Player</th>
    <th>Saves</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Mariano Rivera</td>
    <td>652</td>
  </tr>
  <tr>
    <td>2</td>
    <td>Trevor Hoffman</td>
    <td>601</td>
  </tr>
</table>
```

:::

:::{.column width="50%"}

<table>
  <tr>
    <th>Rank</th>
    <th>Player</th>
    <th>Saves</th>
  </tr>
  <tr>
    <td>1</td>
    <td>Mariano Rivera</td>
    <td>652</td>
  </tr>
  <tr>
    <td>2</td>
    <td>Trevor Hoffman</td>
    <td>601</td>
  </tr>
</table>

:::
::::

## Web Scraping

### Web Scraping{.smaller}

* **Web scraping** is the process of getting information from a website to a dataset, without an API.

* We "simply" search through the raw HTML text, using tags to guides us to what we want.

* (What if what you want isn't nicely in tags?  Regular expressions.)

* The `python` function used to make searching HTML is easier is `BeautifulSoup`

* The challenging parts of webscraping are
    + Identifying the **tag structure** or other *consistent structure* that contains your data.
    + Looping through to find the data items and put them in the right place in a dataset

### Let's try it!

Let's use what we've just learned to scrape some data!

[Colab link](https://colab.research.google.com/drive/1neQvH5uqoX1j74rgCbperbi-HV3uLd8N?usp=sharing)


## Web Scraping and GenAI

### Using GenAI

* GenAI tools can help you "fish" through messy HTML

* As the AI to **write code** for you (which you then test and edit, of course!), not to **scrape the data** for you.

* Why?  
    + It's not great at scraping from multiple pages
    + Hallucinations!

* (Example)

## Ethics of Web Scraping

### Ethical Considerations

* Website owners have to pay a small amount each time you visit a webpage.

* This is usually offset by advertising.

* But when you do web scraping:
    + it is easy to rack up a huge number of webpage visits,
    + and you don't see any ads to offset this cost.
    
* Heavy scraping can hit the website so much or so frequently that it crashes!
    
    
### robots.txt

* Most websites have a `robots.txt` file in the home directory that
indicate which bots are allowed to scrape and which pages they can scrape.

* Here are a few examples:

    -   <http://www.espn.com/robots.txt>

    -   <http://www.nytimes.com/robots.txt>

* However, `robots.txt` is informational only. It doesn't *prevent*
    bots from scraping a webpage.

### Preventing Web Scraping

* Some websites take more drastic measures to prevent web scraping...

![image](./images/scraping.png)

### Your Turn

[This website](http://dmaorg.info/found/15398642_14/clancy.html) has mysterious letters with codes in them.

Can you scrape the site to get a dataset of meta-information that might be useful in solving the puzzles?

Think about things like:

* Date the letter was posted

* URL of the letter

* Filename of the letter 

## Takeaways

### Takeaways

* Web pages are made with **HTML**, and we can use that structure to **scrape** data automatically

* Best case scenario: Your data lives in a `<table>`

* Next best case:  There is some other consistent tag structure

* (Worst case:  Need to use regular expressions)

* **Always** check `robots.txt` before scraping a site!

* **Always** build a small pause into your loop for scraping.

* GenAI can help you with the "fiddly" part of identifying HTML structure.  (But **always** check and test its results!)
